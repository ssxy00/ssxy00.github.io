<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Xinyi Shen">
    <meta name="description" content="arxiv Daily Reading">
    <meta name="keywords" content="NLPer">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Arxiv Daily | Feb 2021"/>
<meta name="twitter:description" content="arxiv Daily Reading"/>

    <meta property="og:title" content="Arxiv Daily | Feb 2021" />
<meta property="og:description" content="arxiv Daily Reading" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://ssxy00.github.io/posts/arxiv-daily-2102/" />
<meta property="article:published_time" content="2021-03-09T18:57:54+08:00" />
<meta property="article:modified_time" content="2021-03-09T18:57:54+08:00" />


    <title>
  Arxiv Daily | Feb 2021 · Xinyi Shen
</title>

    
      <link rel="canonical" href="http://ssxy00.github.io/posts/arxiv-daily-2102/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.1.7/css/fork-awesome.min.css" integrity="sha256-gsmEoJAws/Kd3CjuOQzLie5Q3yshhvmo7YNtBG7aaEY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="/css/coder.min.f01c647a0d25b40da992a37c3376291185eed8a50ced8c26cc2c0bcfe38c97df.css" integrity="sha256-8Bxkeg0ltA2pkqN8M3YpEYXu2KUM7YwmzCwLz&#43;OMl98=" crossorigin="anonymous" media="screen" />
    

    

    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    
      <script src="https://twemoji.maxcdn.com/v/latest/twemoji.min.js" crossorigin="anonymous"></script>
    

    <meta name="generator" content="Hugo 0.62.2" />
  </head>

  
  
  <body class="colorscheme-light"
        onload=" twemoji.parse(document.body); "
  >
    

    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Xinyi Shen
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/contact/">Contact me</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>

<script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>



      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Arxiv Daily | Feb 2021</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime='2021-03-09T18:57:54&#43;08:00'>
                March 9, 2021
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              6-minute read
            </span>
          </div>
          <div class="authors">
    <i class="fa fa-user" aria-hidden="true"></i>
      <a href="/authors/xinyi-shen/">Xinyi Shen</a></div>
          
          
        </div>
      </header>

      <div>
        
        <p>这篇博客记录的是 2021 年 2 月内刷到的 <a href="https://arxiv.org/list/cs.CL/recent">Arxiv cs.CL</a> 感兴趣的文献。</p>
<h2 id="12-feb-21----15-feb-21">12 Feb 21 &ndash; 15 Feb 21</h2>
<p>更新于 22 Mar 2021</p>
<p><a href="https://arxiv.org/pdf/2102.07024.pdf">Interactive Learning from Activity Description</a></p>
<ul>
<li><strong>Author</strong>: Khanh Nguyen, Dipendra Misra, Robert Schapire, Miro Dudík, Patrick Shafto</li>
</ul>
<p>We present a novel interactive learning protocol that enables training request-fulfilling agents by verbally describing their activities.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.07033.pdf">PAQ: 65 Million Probably-Asked Questions and What You Can Do With Them</a></p>
<ul>
<li><strong>Author</strong>: Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich Küttler, Aleksandra Piktus, Pontus Stenetorp, Sebastian Riedel</li>
</ul>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2001.09309.pdf">BERT’s output layer recognizes all hidden layers? Some Intriguing Phenomena and a simple way to boost BERT</a></p>
<ul>
<li><strong>Author</strong>: Wei-Tsung Kao, Tsung-Han Wu,  Po-Han Chi, Chun-Cheng, Hsieh Hung-Yi Lee</li>
</ul>
<p>In this paper, we found that surprisingly the output layer of BERT can reconstruct the input sentence by directly taking each layer of BERT as input, even though the output layer has never seen the input other than the final hidden layer.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2003.02645.pdf"><strong>SentenceMIM: A Latent Variable Language Model</strong></a></p>
<ul>
<li><strong>Author</strong>: Micha Livne, Kevin Swersky, David J. Fleet</li>
</ul>
<p>MIM learning encourages high mutual information between observations and latent variables, and is robust against posterior collapse.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2005.00036.pdf">Improving Factual Consistency Between a Response and Persona Facts</a></p>
<ul>
<li><strong>Author</strong>: Mohsen Mesgar, Edwin Simpson, Iryna Gurevych</li>
<li><strong>Comments</strong>: EACL 2021</li>
</ul>
<p>We propose to finetune these models by reinforcement learning and an efficient reward function that explicitly captures the consistency between a response and persona facts as well as semantic plausibility.</p>
<p>在 PersonaChat 上做了实验</p>
<p>​</p>
<p>​</p>
<h2 id="11-feb-21----12-feb-21">11 Feb 21 &ndash; 12 Feb 21</h2>
<p>更新于 22 Mar 2021</p>
<p><a href="https://arxiv.org/pdf/2008.00623.pdf">DeLighT: Deep and Light-weight Transformer</a></p>
<ul>
<li><strong>Author</strong>: Sachin Mehta, Marjan Ghazvininejad, Srinivasan Iyer, Luke Zettlemoyer, Hannaneh Hajishirzi</li>
<li><strong>Comments</strong>: ICLR 2021</li>
</ul>
<p>Overall, DeLighT networks are 2.5 to 4 times deeper than standard transformer models and yet have fewer parameters and operations.</p>
<p>​</p>
<p>​</p>
<h2 id="10-feb-21----11-feb-21">10 Feb 21 &ndash; 11 Feb 21</h2>
<p>更新于 22 Mar 2021</p>
<p><a href="https://arxiv.org/pdf/2102.05951.pdf">Text Compression-aided Transformer Encoding</a></p>
<ul>
<li><strong>Author</strong>: Zuchao Li, Zhuosheng Zhang, Hai Zhao, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro Sumita</li>
</ul>
<h2 id="4-feb-21----5-feb-21">4 Feb 21 &ndash; 5 Feb 21</h2>
<p>更新于 22 Mar 2021</p>
<p><a href="https://arxiv.org/pdf/2102.03315.pdf">Think you have Solved Direct-Answer Question Answering? Try ARC-DA, the Direct-Answer AI2 Reasoning Challenge</a></p>
<ul>
<li><strong>Author</strong>: Sumithra Bhakthavatsalam, Daniel Khashabi, Tushar Khot, Bhavana Dalvi Mishra, Kyle Richardson, Ashish Sabharwal, Carissa Schoenick, Oyvind Tafjord, Peter Clark</li>
</ul>
<p>ARC-DA is one of the first DA datasets of natural questions that often require reasoning, and where appropriate question decompositions are not evident from the questions themselves.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2009.12061.pdf">An Unsupervised Sentence Embedding Method by Mutual Information Maximization</a></p>
<ul>
<li><strong>Author</strong>: Yan Zhang, Ruidan He, Zuozhu Liu, Kwan Hui Lim, Lidong Bing</li>
<li><strong>Comments</strong>: EMNLP 2020</li>
</ul>
<p>In this paper, we propose a lightweight extension on top of BERT and a novel self-supervised learning objective based on mutual information maximization strategies to derive meaningful sentence embeddings in an unsupervised manner.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/1911.11931.pdf">Evaluating Commonsense in Pre-trained Language Models</a></p>
<ul>
<li><strong>Author</strong>: Xuhui Zhou, Yue Zhang, Leyang Cui, Dandan Huang</li>
<li><strong>Comments</strong>: AAAI 2020</li>
</ul>
<p>We study the commonsense ability of GPT, BERT, XLNet, and RoBERTa by testing them on seven challenging benchmarks.</p>
<p>​</p>
<p>​</p>
<h2 id="3-feb-21----4-feb-21">3 Feb 21 &ndash; 4 Feb 21</h2>
<p>更新于 10 Mar 2021</p>
<p><a href="https://arxiv.org/pdf/2102.02435.pdf">Converse, Focus and Guess - Towards Multi-Document Driven Dialogue</a></p>
<ul>
<li><strong>Author</strong>: Han Liu, Caixia Yuan, Xiaojie Wang, Yushu Yang, Huixing Jiang, Zhongyuan Wang</li>
<li><strong>Comments</strong>: AAAI 2021</li>
</ul>
<p>Task - Multi-Document Driven Dialogue (MD3): an agent can guess the target document that the user is interested in by leading a dialogue.</p>
<p>Dataset - GuessMovie: contains 16,881 documents, each describing a movie, and associated 13,434 dialogues.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.02503.pdf">Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models</a></p>
<ul>
<li><strong>Author</strong>: Alex Tamkin, Miles Brundage, Jack Clark, Deep Ganguli</li>
</ul>
<p>Discussion Summary</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.02574.pdf">Incremental Beam Manipulation for Natural Language Generation</a></p>
<ul>
<li><strong>Author</strong>: James Hargreaves, Andreas Vlachos, Guy Emerson</li>
<li><strong>Comments</strong>: EACL 2021</li>
</ul>
<p>This paper proposes incremental beam manipulation, i.e. reranking the hypotheses in the beam during decoding instead of only at the end.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.02779.pdf">Unifying Vision-and-Language Tasks via Text Generation</a></p>
<ul>
<li><strong>Author</strong>: Jaemin Cho, Jie Lei, Hao Tan, Mohit Bansal</li>
</ul>
<p>We propose a unified framework that learns different tasks in a single architecture with the same language modeling objective, i.e., multimodal conditional text generation.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2005.02178.pdf">IsoBN: Fine-Tuning BERT with Isotropic Batch Normalization</a></p>
<ul>
<li><strong>Author</strong>: Wenxuan Zhou, Bill Yuchen Lin, Xiang Ren</li>
<li><strong>Comments</strong>: AAAI 2021</li>
</ul>
<p>In this paper, we analyze the isotropy of the pre-trained [CLS] embeddings of PTLMs with straightforward visualization, and point out two major issues: high variance in their standard deviation, and high correlation between different dimensions. We also propose a new network regularization method, isotropic batch normalization (IsoBN) to address the issues, towards learning more isotropic representations in fine-tuning by dynamically penalizing dominating principal components.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2007.00655.pdf">Knowledge-Aware Language Model Pretraining</a></p>
<ul>
<li><strong>Author</strong>: Corby Rosset, Chenyan Xiong, Minh Phan, Xia Song, Paul Bennett, Saurabh Tiwary</li>
</ul>
<p>In this paper we incorporate knowledge-awareness in language model pretraining without changing the transformer architecture, inserting explicit knowledge layers, or adding external storage of semantic information. Rather, we simply signal the existence of entities to the input of the transformer in pretraining, with an entityextended tokenizer; and at the output, with an additional entity prediction task.</p>
<p>​</p>
<p>​</p>
<h2 id="2-feb-21----3-feb-21">2 Feb 21 &ndash; 3 Feb 21</h2>
<p>更新于 9 Mar 2021</p>
<p><a href="https://arxiv.org/pdf/2102.01951.pdf">Pitfalls of Static Language Modelling</a></p>
<ul>
<li><strong>Author</strong>: Angeliki Lazaridou, Adhiguna Kuncoro, Elena Gribovskaya, Devang Agrawal, Adam Liška, Tayfun Terzi, Mai Gimenez, Cyprien de Masson d’Autume, Sebastian Ruder, Dani Yogatama, Kris Cao, Tomas Kocisky, Susannah Young, Phil Blunsom</li>
</ul>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.02096.pdf">Learning to Select External Knowledge with Multi-Scale Negative Sampling</a></p>
<ul>
<li><strong>Author</strong>: Huang He, Hua Lu, Siqi Bao, Fan Wang, Hua Wu, Zhengyu Niu, Haifeng Wang</li>
<li><strong>Comments</strong>: AAAI-21 DSTC9 Workshop</li>
</ul>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.02191.pdf">DiSCoL: Toward Engaging Dialogue Systems through Conversational Line Guided Response Generation</a></p>
<ul>
<li><strong>Author</strong>: Sarik Ghazarian, Zixi Liu, Tuhin Chakrabarty, Xuezhe Ma, Aram Galstyan, Nanyun Peng</li>
</ul>
<ol>
<li>predicting relevant and informative convlines for dialogue contexts and 2) generating high-quality responses conditioned on the predicted convlines.</li>
</ol>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2007.01282.pdf">Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering</a></p>
<ul>
<li><strong>Author</strong>: Gautier Izacard, Edouard Grave</li>
</ul>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2010.02329.pdf">InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective</a></p>
<ul>
<li><strong>Author</strong>: Boxin Wang, Shuohang Wang, Yu Cheng, Zhe Gan, Ruoxi Jia, Bo Li, Jingjing Liu</li>
<li><strong>Comments</strong>: ICLR 2021</li>
</ul>
<p>InfoBERT contains two mutual-information-based regularizers for model training: (i) an Information Bottleneck regularizer, which suppresses noisy mutual information between the input and the feature representation; and (ii) an Anchored Feature regularizer, which increases the mutual information between local stable features and global features.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.01672.pdf"><strong>The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics</strong></a></p>
<ul>
<li><strong>Author</strong>: Sebastian Gehrmann et al. （太多了）</li>
</ul>
<p>NLG 评估</p>
<p>​</p>
<p>​</p>
<h2 id="1-feb-21----2-feb-21">1 Feb 21 &ndash; 2 Feb 21</h2>
<p>更新于 9 Mar 2021</p>
<p><a href="https://arxiv.org/pdf/2103.03125.pdf">Advances in Multi-turn Dialogue Comprehension: A Survey</a></p>
<ul>
<li><strong>Author</strong>: Zhuosheng Zhang, Hai Zhao</li>
</ul>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      
  <footer class="footer">
    <section class="container">
      
      
        ©
        
          2020 -
        
        2021
         Xinyi Shen 
      
      
         · 
        Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
      
      
        
      
    </section>
  </footer>


    </main>

    

    

    

    

    

    
  </body>

</html>
