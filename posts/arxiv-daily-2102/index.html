<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Xinyi Shen">
    <meta name="description" content="arxiv Daily Reading">
    <meta name="keywords" content="NLPer">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Arxiv Daily | Feb 2021"/>
<meta name="twitter:description" content="arxiv Daily Reading"/>

    <meta property="og:title" content="Arxiv Daily | Feb 2021" />
<meta property="og:description" content="arxiv Daily Reading" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://ssxy00.github.io/posts/arxiv-daily-2102/" />
<meta property="article:published_time" content="2021-03-09T18:57:54+08:00" />
<meta property="article:modified_time" content="2021-03-09T18:57:54+08:00" />


    <title>
  Arxiv Daily | Feb 2021 · Xinyi Shen
</title>

    
      <link rel="canonical" href="http://ssxy00.github.io/posts/arxiv-daily-2102/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.1.7/css/fork-awesome.min.css" integrity="sha256-gsmEoJAws/Kd3CjuOQzLie5Q3yshhvmo7YNtBG7aaEY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="/css/coder.min.f01c647a0d25b40da992a37c3376291185eed8a50ced8c26cc2c0bcfe38c97df.css" integrity="sha256-8Bxkeg0ltA2pkqN8M3YpEYXu2KUM7YwmzCwLz&#43;OMl98=" crossorigin="anonymous" media="screen" />
    

    

    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    
      <script src="https://twemoji.maxcdn.com/v/latest/twemoji.min.js" crossorigin="anonymous"></script>
    

    <meta name="generator" content="Hugo 0.62.2" />
  </head>

  
  
  <body class="colorscheme-light"
        onload=" twemoji.parse(document.body); "
  >
    

    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Xinyi Shen
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/contact/">Contact me</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>

<script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>



      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Arxiv Daily | Feb 2021</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime='2021-03-09T18:57:54&#43;08:00'>
                March 9, 2021
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              3-minute read
            </span>
          </div>
          <div class="authors">
    <i class="fa fa-user" aria-hidden="true"></i>
      <a href="/authors/xinyi-shen/">Xinyi Shen</a></div>
          
          
        </div>
      </header>

      <div>
        
        <p>这篇博客记录的是 2021 年 2 月内刷到的 <a href="https://arxiv.org/list/cs.CL/recent">Arxiv cs.CL</a> 感兴趣的文献。</p>
<h2 id="3-feb-21----4-feb-21">3 Feb 21 &ndash; 4 Feb 21</h2>
<p>更新于 10 Mar 2021</p>
<p><a href="https://arxiv.org/pdf/2102.02435.pdf">Converse, Focus and Guess - Towards Multi-Document Driven Dialogue</a></p>
<ul>
<li><strong>Author</strong>: Han Liu, Caixia Yuan, Xiaojie Wang, Yushu Yang, Huixing Jiang, Zhongyuan Wang</li>
<li><strong>Comments</strong>: AAAI 2021</li>
</ul>
<p>Task - Multi-Document Driven Dialogue (MD3): an agent can guess the target document that the user is interested in by leading a dialogue.</p>
<p>Dataset - GuessMovie: contains 16,881 documents, each describing a movie, and associated 13,434 dialogues.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.02503.pdf">Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models</a></p>
<ul>
<li><strong>Author</strong>: Alex Tamkin, Miles Brundage, Jack Clark, Deep Ganguli</li>
</ul>
<p>Discussion Summary</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.02574.pdf">Incremental Beam Manipulation for Natural Language Generation</a></p>
<ul>
<li><strong>Author</strong>: James Hargreaves, Andreas Vlachos, Guy Emerson</li>
<li><strong>Comments</strong>: EACL 2021</li>
</ul>
<p>This paper proposes incremental beam manipulation, i.e. reranking the hypotheses in the beam during decoding instead of only at the end.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.02779.pdf">Unifying Vision-and-Language Tasks via Text Generation</a></p>
<ul>
<li><strong>Author</strong>: Jaemin Cho, Jie Lei, Hao Tan, Mohit Bansal</li>
</ul>
<p>We propose a unified framework that learns different tasks in a single architecture with the same language modeling objective, i.e., multimodal conditional text generation.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2005.02178.pdf">IsoBN: Fine-Tuning BERT with Isotropic Batch Normalization</a></p>
<ul>
<li><strong>Author</strong>: Wenxuan Zhou, Bill Yuchen Lin, Xiang Ren</li>
<li><strong>Comments</strong>: AAAI 2021</li>
</ul>
<p>In this paper, we analyze the isotropy of the pre-trained [CLS] embeddings of PTLMs with straightforward visualization, and point out two major issues: high variance in their standard deviation, and high correlation between different dimensions. We also propose a new network regularization method, isotropic batch normalization (IsoBN) to address the issues, towards learning more isotropic representations in fine-tuning by dynamically penalizing dominating principal components.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2007.00655.pdf">Knowledge-Aware Language Model Pretraining</a></p>
<ul>
<li><strong>Author</strong>: Corby Rosset, Chenyan Xiong, Minh Phan, Xia Song, Paul Bennett, Saurabh Tiwary</li>
</ul>
<p>In this paper we incorporate knowledge-awareness in language model pretraining without changing the transformer architecture, inserting explicit knowledge layers, or adding external storage of semantic information. Rather, we simply signal the existence of entities to the input of the transformer in pretraining, with an entityextended tokenizer; and at the output, with an additional entity prediction task.</p>
<p>​</p>
<p>​</p>
<h2 id="2-feb-21----3-feb-21">2 Feb 21 &ndash; 3 Feb 21</h2>
<p>更新于 9 Mar 2021</p>
<p><a href="https://arxiv.org/pdf/2102.01951.pdf">Pitfalls of Static Language Modelling</a></p>
<ul>
<li><strong>Author</strong>: Angeliki Lazaridou, Adhiguna Kuncoro, Elena Gribovskaya, Devang Agrawal, Adam Liška, Tayfun Terzi, Mai Gimenez, Cyprien de Masson d’Autume, Sebastian Ruder, Dani Yogatama, Kris Cao, Tomas Kocisky, Susannah Young, Phil Blunsom</li>
</ul>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.02096.pdf">Learning to Select External Knowledge with Multi-Scale Negative Sampling</a></p>
<ul>
<li><strong>Author</strong>: Huang He, Hua Lu, Siqi Bao, Fan Wang, Hua Wu, Zhengyu Niu, Haifeng Wang</li>
<li><strong>Comments</strong>: AAAI-21 DSTC9 Workshop</li>
</ul>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.02191.pdf">DiSCoL: Toward Engaging Dialogue Systems through Conversational Line Guided Response Generation</a></p>
<ul>
<li><strong>Author</strong>: Sarik Ghazarian, Zixi Liu, Tuhin Chakrabarty, Xuezhe Ma, Aram Galstyan, Nanyun Peng</li>
</ul>
<ol>
<li>predicting relevant and informative convlines for dialogue contexts and 2) generating high-quality responses conditioned on the predicted convlines.</li>
</ol>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2007.01282.pdf">Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering</a></p>
<ul>
<li><strong>Author</strong>: Gautier Izacard, Edouard Grave</li>
</ul>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2010.02329.pdf">InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective</a></p>
<ul>
<li><strong>Author</strong>: Boxin Wang, Shuohang Wang, Yu Cheng, Zhe Gan, Ruoxi Jia, Bo Li, Jingjing Liu</li>
<li><strong>Comments</strong>: ICLR 2021</li>
</ul>
<p>InfoBERT contains two mutual-information-based regularizers for model training: (i) an Information Bottleneck regularizer, which suppresses noisy mutual information between the input and the feature representation; and (ii) an Anchored Feature regularizer, which increases the mutual information between local stable features and global features.</p>
<p>​</p>
<p><a href="https://arxiv.org/pdf/2102.01672.pdf"><strong>The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics</strong></a></p>
<ul>
<li><strong>Author</strong>: Sebastian Gehrmann et al. （太多了）</li>
</ul>
<p>NLG 评估</p>
<p>​</p>
<p>​</p>
<h2 id="1-feb-21----2-feb-21">1 Feb 21 &ndash; 2 Feb 21</h2>
<p>更新于 9 Mar 2021</p>
<p><a href="https://arxiv.org/pdf/2103.03125.pdf">Advances in Multi-turn Dialogue Comprehension: A Survey</a></p>
<ul>
<li><strong>Author</strong>: Zhuosheng Zhang, Hai Zhao</li>
</ul>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      
  <footer class="footer">
    <section class="container">
      
      
        ©
        
          2020 -
        
        2021
         Xinyi Shen 
      
      
         · 
        Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
      
      
        
      
    </section>
  </footer>


    </main>

    

    

    

    

    

    
  </body>

</html>
